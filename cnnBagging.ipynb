{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Training estimator #1\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 3s 72ms/step - loss: 0.8867 - accuracy: 0.4364 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6752 - accuracy: 0.5500 - val_loss: 0.7788 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6484 - accuracy: 0.6136 - val_loss: 0.7260 - val_accuracy: 0.4625\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5408 - accuracy: 0.8136 - val_loss: 0.7527 - val_accuracy: 0.4750\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4027 - accuracy: 0.8727 - val_loss: 0.8854 - val_accuracy: 0.5375\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2852 - accuracy: 0.9000 - val_loss: 1.0884 - val_accuracy: 0.5500\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2402 - accuracy: 0.9364 - val_loss: 1.7040 - val_accuracy: 0.5250\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3192 - accuracy: 0.8545 - val_loss: 0.9510 - val_accuracy: 0.5500\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2294 - accuracy: 0.9409 - val_loss: 1.2457 - val_accuracy: 0.5375\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1304 - accuracy: 0.9636 - val_loss: 1.4316 - val_accuracy: 0.5500\n",
      "Training estimator #2\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 37ms/step - loss: 0.7722 - accuracy: 0.5227 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6609 - accuracy: 0.6818 - val_loss: 0.7265 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6068 - accuracy: 0.7136 - val_loss: 0.7053 - val_accuracy: 0.4375\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5246 - accuracy: 0.7545 - val_loss: 0.7453 - val_accuracy: 0.4250\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3996 - accuracy: 0.8545 - val_loss: 0.8871 - val_accuracy: 0.5375\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3161 - accuracy: 0.8773 - val_loss: 0.8671 - val_accuracy: 0.5250\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2309 - accuracy: 0.9091 - val_loss: 0.9642 - val_accuracy: 0.5125\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1374 - accuracy: 0.9636 - val_loss: 1.2545 - val_accuracy: 0.5250\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0944 - accuracy: 0.9682 - val_loss: 1.3804 - val_accuracy: 0.5750\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0616 - accuracy: 0.9909 - val_loss: 1.3618 - val_accuracy: 0.5625\n",
      "Training estimator #3\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 38ms/step - loss: 0.7870 - accuracy: 0.4955 - val_loss: 0.6918 - val_accuracy: 0.5125\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6705 - accuracy: 0.6500 - val_loss: 0.6919 - val_accuracy: 0.5250\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6454 - accuracy: 0.5773 - val_loss: 0.7001 - val_accuracy: 0.5125\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5537 - accuracy: 0.7682 - val_loss: 0.7175 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.4353 - accuracy: 0.8364 - val_loss: 0.8437 - val_accuracy: 0.4750\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3094 - accuracy: 0.9318 - val_loss: 0.9428 - val_accuracy: 0.5375\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2157 - accuracy: 0.9364 - val_loss: 1.0664 - val_accuracy: 0.5125\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1644 - accuracy: 0.9545 - val_loss: 1.2707 - val_accuracy: 0.5125\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1020 - accuracy: 0.9773 - val_loss: 1.3356 - val_accuracy: 0.4750\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0511 - accuracy: 0.9955 - val_loss: 1.5324 - val_accuracy: 0.4875\n",
      "Training estimator #4\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 38ms/step - loss: 0.8762 - accuracy: 0.5955 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6919 - accuracy: 0.5227 - val_loss: 0.6941 - val_accuracy: 0.4750\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6866 - accuracy: 0.5773 - val_loss: 0.6910 - val_accuracy: 0.4750\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6668 - accuracy: 0.6409 - val_loss: 0.6899 - val_accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6188 - accuracy: 0.6864 - val_loss: 0.8023 - val_accuracy: 0.5125\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5990 - accuracy: 0.6364 - val_loss: 0.7512 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5163 - accuracy: 0.7864 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.7901 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3398 - accuracy: 0.8773 - val_loss: 1.0022 - val_accuracy: 0.5250\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2805 - accuracy: 0.8727 - val_loss: 0.9851 - val_accuracy: 0.5000\n",
      "Training estimator #5\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 35ms/step - loss: 0.7798 - accuracy: 0.5045 - val_loss: 0.6961 - val_accuracy: 0.4750\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6809 - accuracy: 0.6136 - val_loss: 0.7107 - val_accuracy: 0.4875\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6340 - accuracy: 0.6773 - val_loss: 0.7299 - val_accuracy: 0.4500\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5553 - accuracy: 0.7818 - val_loss: 0.8131 - val_accuracy: 0.4125\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.4489 - accuracy: 0.8318 - val_loss: 0.9026 - val_accuracy: 0.4375\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3399 - accuracy: 0.8636 - val_loss: 1.1120 - val_accuracy: 0.4625\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2508 - accuracy: 0.9273 - val_loss: 1.3200 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1561 - accuracy: 0.9636 - val_loss: 1.6645 - val_accuracy: 0.4875\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1152 - accuracy: 0.9727 - val_loss: 1.4659 - val_accuracy: 0.4875\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0637 - accuracy: 0.9864 - val_loss: 1.8509 - val_accuracy: 0.4625\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002D5FDDFEB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Bagging ensemble test accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. 先把資料全部讀進來 (記得適當調整 memory footprint)\n",
    "def load_data(generator, num_samples):\n",
    "    X, y = [], []\n",
    "    for batch_x, batch_y in generator:\n",
    "        X.append(batch_x); y.append(batch_y)\n",
    "        if len(X)*generator.batch_size >= num_samples:\n",
    "            break\n",
    "    X = np.vstack(X); y = np.concatenate(y)\n",
    "    return X, y\n",
    "\n",
    "# 2. 包裝 CNN 結構成函式\n",
    "def build_model(input_shape=(128,128,3)):\n",
    "    m = models.Sequential([\n",
    "        layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    m.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return m\n",
    "\n",
    "# 3. 建立 ImageDataGenerator 與 generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=15,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   fill_mode='nearest')\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    'train', target_size=(128,128), batch_size=32, class_mode='binary'\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    'test',  target_size=(128,128), batch_size=32, class_mode='binary', shuffle=False\n",
    ")\n",
    "\n",
    "# 4. 把資料一次 load 出來\n",
    "X_train, y_train = load_data(train_gen, train_gen.samples)\n",
    "X_test,  y_test  = load_data(test_gen,  test_gen.samples)\n",
    "\n",
    "# 5. Bagging 參數\n",
    "n_estimators = 5\n",
    "ensemble = []\n",
    "\n",
    "# 6. 針對每個子模型做 bootstrap 取樣並訓練\n",
    "for i in range(n_estimators):\n",
    "    print(f\"Training estimator #{i+1}\")\n",
    "    # Bootstrap sample\n",
    "    idx = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_bs, y_bs = X_train[idx], y_train[idx]\n",
    "    \n",
    "    # 建立、訓練子模型\n",
    "    m = build_model(input_shape=(128,128,3))\n",
    "    m.fit(\n",
    "        X_bs, y_bs,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=1\n",
    "    )\n",
    "    ensemble.append(m)\n",
    "\n",
    "# 7. 預測並平均機率\n",
    "all_preds = np.stack([m.predict(X_test).ravel() for m in ensemble], axis=0)\n",
    "avg_prob  = np.mean(all_preds, axis=0)\n",
    "y_pred    = (avg_prob > 0.5).astype(int)\n",
    "\n",
    "# 8. 計算整體準確率\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Bagging ensemble test accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
